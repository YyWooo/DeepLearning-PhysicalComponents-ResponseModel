{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Given parameters\n",
    "circuit = 'nonlinear'  # 可选值 [nonlinear, differential]          # nonlinear : 非线性电路，          differential ： 微分电路\n",
    "model_structure = 'CNN'  # 可选值 [CNN, REG] \n",
    "input_dim = 100  # 可选值 [25, 50, 100]\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Construct the model name\n",
    "model_name = f'{circuit}_{input_dim}_{model_structure}'\n",
    "model_filename = model_name + '.pth'\n",
    "model_existed = False\n",
    "\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = '../pretrained_network/'\n",
    "\n",
    "# Check if the pretrained model exists\n",
    "if os.path.exists(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    if model_filename in files:\n",
    "        model_filename = os.path.join(folder_path, model_filename)\n",
    "        # print(f\"File '{model_filename}' exists in the folder '{folder_path}'.\")\n",
    "        model_existed = True\n",
    "\n",
    "\n",
    "# If the file path exists then use the pretrained model\n",
    "if model_existed:\n",
    "    print(f\"Model file path: {model_filename}\")\n",
    "else:\n",
    "    print('Pretrained model does not exist')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove quantity units from columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate units in dataset (msec, mV, uV, nV, pV, aV), Keep only their values\n",
    "def remove_units(value):\n",
    "    parts = value.split()\n",
    "    if (len(parts) == 2 and parts[1] == 'mV') or (len(parts) == 2 and parts[1] == 'msec'):\n",
    "        return float(parts[0]) / 1000\n",
    "    elif (len(parts) == 2 and parts[1] == 'uV') or (len(parts) == 2 and parts[1] == 'usec'):\n",
    "        return float(parts[0]) / 1e6\n",
    "    elif (len(parts) == 2 and parts[1] == 'nV'):\n",
    "        return float(parts[0]) / 1e9\n",
    "    elif (len(parts) == 2 and parts[1] == 'pV'):\n",
    "        return float(parts[0]) / 1e12\n",
    "    elif (len(parts) == 2 and parts[1] == 'aV'):\n",
    "        return float(parts[0]) / 1e18\n",
    "    else:\n",
    "        return float(parts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all dataset into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if circuit == 'nonlinear':\n",
    "    filenames = [\n",
    "    r'nonlinear_data\\nonlinear_50_sine.csv',        # Sine wave data\n",
    "    r'nonlinear_data\\nonlinear_50_cosine.csv',      # Cosine wave data    \n",
    "    r'nonlinear_data\\nonlinear_50_expoDec.csv',     # Exponentially decreasing waveform data\n",
    "    r'nonlinear_data\\nonlinear_50_expoInc.csv',     # Exponentially increasing waveform data\n",
    "    r'nonlinear_data\\nonlinear_50_combined.csv',    # Combined waveform data\n",
    "    r'nonlinear_data\\nonlinear_50_test.csv',        # Test set for evaluation\n",
    "    # Uncomment the following line to use the updated test set, if use the updated test set, we need to comment original testset:\n",
    "    # r'nonlinear_data\\nonlinear_50_test_updated.csv'  # Updated Test Set: Lower Input Voltage Frequency to Activate Second JFET and Ensure Uncorrupted Waveform\n",
    "    ]   \n",
    "else: \n",
    "    filenames = [\n",
    "        r'differential_data\\differ_50_sine.csv',\n",
    "        r'differential_data\\differ_50_cosine.csv',\n",
    "        r'differential_data\\differ_50_expoDec.csv',\n",
    "        r'differential_data\\differ_50_expoInc.csv',\n",
    "        r'differential_data\\differ_50_combined.csv',\n",
    "        r'differential_data\\differ_50_test.csv'  # Test set\n",
    "    ]\n",
    "\n",
    "# Read, process, and store each file\n",
    "dataframes = []\n",
    "for filename in filenames:\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    # Drop the first unnamed column if it exists\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.drop(columns='Unnamed: 0')\n",
    "\n",
    "    # Drop the first column and rename columns\n",
    "    df = df.drop(columns=df.columns[0])\n",
    "    df.columns = ['time', 'v_in', 'v_out']\n",
    "\n",
    "    # Convert units to base values\n",
    "    df = df.map(remove_units)\n",
    "\n",
    "    # Append the processed DataFrame to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "overall_df = pd.concat(dataframes, ignore_index=True)\n",
    "df = overall_df\n",
    "\n",
    "# Print the first 10 rows of dataset\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to numpy\n",
    "X = df['v_in'].to_numpy()\n",
    "y = df['v_out'].to_numpy()\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_and_convert(arr):\n",
    "    scaler = MinMaxScaler()\n",
    "    # Reshape the array for MinMaxScaler\n",
    "    arr = arr.reshape(-1, 1)\n",
    "    # Normalize the entire array\n",
    "    normalized_arr = scaler.fit_transform(arr)\n",
    "    # Convert the normalized array to a PyTorch tensor\n",
    "    return torch.from_numpy(normalized_arr).float()\n",
    "\n",
    "# Normalize\n",
    "X_normalized = normalize_and_convert(X)\n",
    "y_normalized = normalize_and_convert(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Trainset and Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "delta_t = 2e-2\n",
    "batches = int(len(X_normalized) / input_dim)\n",
    "t = np.arange(0, 2e-2*input_dim, delta_t)\n",
    "\n",
    "# Separate into batches \n",
    "X_reshaped = X_normalized.view(batches, input_dim)  \n",
    "y_reshaped = y_normalized.view(batches, input_dim)  \n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_reshaped, test_size=50/300, shuffle=False)\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Plot the waveform of each dataset\n",
    "for batch_idx, (inputs, targets) in enumerate(train_dataset):\n",
    "    plt.title('Train Set')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Input Voltage')\n",
    "    plt.plot(t, inputs, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "for batch_idx, (inputs, targets) in enumerate(train_dataset):\n",
    "    plt.title('Train Set')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Output Voltage')\n",
    "    plt.plot(t, targets)\n",
    "plt.show()\n",
    "\n",
    "for batch_idx, (inputs, targets) in enumerate(test_dataset):\n",
    "    plt.title('Test Set')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Input Voltage')\n",
    "    plt.plot(t, inputs)\n",
    "plt.show()\n",
    "\n",
    "for batch_idx, (inputs, targets) in enumerate(test_dataset):\n",
    "    plt.title('Test Set')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Output Voltage')\n",
    "    plt.plot(t, targets)\n",
    "plt.show()\n",
    "\n",
    "# Print the length of train and test sets\n",
    "print(f\"Length of Train Set: {len(train_dataset)}\")\n",
    "print(f\"Length of Test Set: {len(test_dataset)}\")\n",
    "\n",
    "# Create DataLoaders for training and testing\n",
    "train_loader = DataLoader(train_dataset, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Structure and Training  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Nerual Network : CNN \n",
    "class VoltageNetConv(nn.Module):\n",
    "    def __init__(self, input_channels, input_dim):\n",
    "        super(VoltageNetConv, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=3, padding=1)    # Keeps the length the same\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)                # Keeps the length the same\n",
    "        self.flatten = nn.Flatten(start_dim=0)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(64 * input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with ReLU activation\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "\n",
    "        # Flatten the output from the conv layers to feed into the fully connected layers\n",
    "        x = self.flatten(x).unsqueeze(0)\n",
    "\n",
    "        # Apply fully connected layers\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Nerual Network : Regression \n",
    "class VoltageNetReg(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(VoltageNetReg, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)  # Input layer to hidden layer\n",
    "        self.relu = nn.ReLU()           # Activation function\n",
    "        self.fc2 = nn.Linear(128, 64)  # Hidden layer to output layer\n",
    "        self.fc3 = nn.Linear(64, input_dim)  # Hidden layer to output layer\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "if model_structure == 'CNN':\n",
    "    model = VoltageNetConv(1 , input_dim) # There is only 1 channel input\n",
    "else:\n",
    "    model = VoltageNetReg(input_dim)\n",
    "print(model)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Move network to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "num_epoch = 200\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "avg_loss_values = []\n",
    "\n",
    "if not model_existed:\n",
    "    # Training loop\n",
    "    for epoch in range(num_epoch):\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            optimizer.zero_grad()                   # Clear gradients for the next train\n",
    "            outputs = model(inputs)                 # Forward pass\n",
    "            train_loss = loss(outputs, targets)     # Calculate loss\n",
    "            train_loss.backward()                   # Backward pass\n",
    "            optimizer.step()                        # Optimize the weights\n",
    "\n",
    "        # Calculate and store the average training loss for this epoch\n",
    "        train_loss_values.append(train_loss.item())\n",
    "\n",
    "        # Evaluate the model on the test data\n",
    "        model.eval()                                # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            test_loss_sum = 0.0\n",
    "            num_batches = 0\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = model(inputs)             # Forward pass\n",
    "                test_loss = loss(outputs, targets)  # Calculate loss\n",
    "                test_loss_sum += test_loss.item()\n",
    "                num_batches += 1\n",
    "\n",
    "            # Calculate and store the average test loss for this epoch\n",
    "            avg_test_loss = test_loss_sum / num_batches\n",
    "            test_loss_values.append(avg_test_loss)\n",
    "\n",
    "        # Print loss every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epoch}], Training Loss: {train_loss.item():.4f}, Test Loss: {avg_test_loss:.4f}')\n",
    "        \n",
    "\n",
    "\n",
    "    # Save trained network's parameters\n",
    "    torch.save(model.state_dict(), model_filename)\n",
    "\n",
    "    # Plotting the training and test loss over epochs\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_loss_values, label='Training Loss')\n",
    "    plt.plot(test_loss_values, label='Test Loss')\n",
    "    plt.title('Training and Test Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction & Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if model_existed:\n",
    "    model.load_state_dict(torch.load(model_filename))\n",
    "else: # if model does not exist, save the state of trained model\n",
    "    torch.save(model.state_dict(), model_name + '.pth')\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Test loss\n",
    "loss = nn.MSELoss()\n",
    "test_loss, test_loss_sum = 0, 0\n",
    "\n",
    "# Containers for data\n",
    "test_inputs = []\n",
    "actual_outputs = []\n",
    "predicted_outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs\n",
    "        outputs = model(inputs)\n",
    "        targets = targets\n",
    "\n",
    "        # Calculate the test loss\n",
    "        test_inputs.append(inputs)\n",
    "        test_loss = loss(outputs, targets)\n",
    "        test_loss_sum += test_loss.item()\n",
    "\n",
    "        # Store data for plotting\n",
    "        actual_outputs.append(targets)\n",
    "        predicted_outputs.append(outputs)\n",
    "\n",
    "print(f'Test Loss: {test_loss_sum/50}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting Prediction Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting lists of batches into a single tensor\n",
    "\n",
    "test_inputs = torch.cat(test_inputs, dim=0).cpu()\n",
    "actual_outputs = torch.cat(actual_outputs, dim=0).cpu()\n",
    "predicted_outputs = torch.cat(predicted_outputs, dim=0).cpu()\n",
    "\n",
    "# Compute and plot correlation coefficient and its CDF\n",
    "correlation_coefficients = []\n",
    "\n",
    "# Plotting\n",
    "for idx in range(test_inputs.shape[0]):\n",
    "    # Calculate the Pearson correlation coefficient for each sample\n",
    "    if actual_outputs[idx].numel() > 1:  # Ensure there are enough data points to compute correlation\n",
    "        correlation = np.corrcoef(actual_outputs[idx].numpy(), predicted_outputs[idx].numpy())[0, 1]\n",
    "        correlation_coefficients.append(correlation)\n",
    "\n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Plot 1: Actual vs Predicted Output Voltage\n",
    "    axs[0].plot(t, test_inputs[idx], label='Input Waveform')\n",
    "    axs[0].plot(t, actual_outputs[idx], label='Actual Output Waveform')\n",
    "    axs[0].plot(t, predicted_outputs[idx], linestyle='--', label='Predicted Output Waveform')\n",
    "    axs[0].set_title(f'Sample {idx + 1} - Comparison of Actual and Predicted Waveform')\n",
    "    axs[0].set_xlabel('Time')\n",
    "    axs[0].set_ylabel('Voltage')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # Plot 2: Correlation between Actual and Predicted Voltages\n",
    "    axs[1].scatter(actual_outputs[idx].numpy(), predicted_outputs[idx].numpy(), alpha=0.5)\n",
    "    axs[1].set_title(f'Sample {idx + 1} - Correlation between Actual and Predicted Waveform')\n",
    "    axs[1].set_xlabel('Actual Waveform')\n",
    "    axs[1].set_ylabel('Predicted Waveform')\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the figure containing both subplots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw CDF Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot CDF\n",
    "def plot_cdf(data, label, color):\n",
    "    sorted_data = np.sort(data)\n",
    "    cdf = np.arange(len(sorted_data)) / float(len(sorted_data))\n",
    "    plt.plot(sorted_data, cdf, label=label, color=color)\n",
    "    \n",
    "# Plot CDF of correlation coefficients\n",
    "plt.figure(figsize=(6, 6))\n",
    "plot_cdf(np.array(correlation_coefficients), 'Correlation Coefficient', 'blue')\n",
    "plt.title('CDF of Correlation Coefficients')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.ylabel('Cumulative Proportion')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
